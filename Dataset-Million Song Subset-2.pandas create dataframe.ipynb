{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read parts of the MSD into tables\n",
    "\n",
    "This notebook creates a pandas dataframe from the `/metadata/songs` and `/analysis/songs` tables in the HDF5 files. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pandas` module requires code from the _PyTables_ package. To load this package into Python from a console:\n",
    "\n",
    "> `$ conda install --name python3 PyTables`\n",
    "\n",
    "This only needs to happen once on your computer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import itertools as it\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import operator \n",
    "import functools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define utility functions\n",
    "\n",
    "The `get_filenames` function recursively gets the names of all files in a given directory `path` and all of its subdirectories. The function returns a multi-level list if `path` contains subdirectories. The `unlist` function flattens the list by removing one level. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_filenames(path):\n",
    "    return([get_filenames(path+\"/\"+entry.name)\n",
    "            if entry.is_dir() \n",
    "            else path+\"/\"+entry.name \n",
    "            for entry \n",
    "            in os.scandir(path)\n",
    "           ])\n",
    "\n",
    "def unlist(alist):\n",
    "    return(list(it.chain.from_iterable(alist)\n",
    "               )\n",
    "          )\n",
    "\n",
    "def var_list(base,numof):\n",
    "    return([base+str(ndx) for ndx in range(numof)]\n",
    "          )\n",
    "\n",
    "def h1d_array(in_array,n): \n",
    "    # n1d is the number of elements in `in_array`\n",
    "    n1d = functools.reduce(operator.mul,\n",
    "                           list(in_array.shape))\n",
    "    # return a 1 row 2D array with `n` columns\n",
    "    b = np.ndarray(shape=(1,n1d),\n",
    "                   buffer=in_array,\n",
    "                   dtype=in_array.dtype\n",
    "                  )[0:1,0:n]\n",
    "    return(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `make_1row_df` function returns a single row dataframe and takes the following input:\n",
    "\n",
    "- `filename`: full path file name of an MSD HDF5 file containing data for a single song\n",
    "- `metadata_vars`: list of variable names from `/metadata/songs`\n",
    "- `analysis_vars`: list of variable names from `/analysis/songs`\n",
    "- `remove`: \n",
    "    - if `False` the variables listed in the last two parameters are retrieved from the input file\n",
    "    - if `True` all variables except those listed are retrieved from the input file\n",
    "\n",
    "See comments in the code for further details. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_1row_df(filename='', metadata_vars=[], analysis_vars=[], remove=False):\n",
    "    # open `filename` as a HDF5 file\n",
    "    store = pd.HDFStore(filename,\"r\")\n",
    "    if remove==True:\n",
    "        # `metadata_vars` and `analysis_vars` contain the variables to remove\n",
    "        metadata_vars = list({item for item \n",
    "                                  in list(store.root.metadata.songs.read().dtype.names) \n",
    "                                  if item not in metadata_vars})\n",
    "        analysis_vars = list({item for item \n",
    "                                  in list(store.root.analysis.songs.read().dtype.names) \n",
    "                                  if item not in analysis_vars})\n",
    "    # else: `metadata_vars` and `analysis_vars` contain the variables to keep\n",
    "    \n",
    "    # retrieve the first `n` values as a horizontal array of 1 dimension\n",
    "    segments_pitches = h1d_array(store.root.analysis.segments_pitches.read(),36)\n",
    "    segments_timbre  = h1d_array(store.root.analysis.segments_timbre.read(),36)\n",
    "    bars_confidence  = h1d_array(store.root.analysis.bars_confidence.read(),10)\n",
    "    artist_terms     = h1d_array(store.root.metadata.artist_terms.read(),3)\n",
    "    \n",
    "    # store these values as variables in single dataframes\n",
    "    at_df = pd.DataFrame(artist_terms    ,columns=var_list('at_',artist_terms    .shape[1]))\n",
    "    bc_df = pd.DataFrame(bars_confidence ,columns=var_list('bc_',bars_confidence .shape[1]))\n",
    "    sp_df = pd.DataFrame(segments_pitches,columns=var_list('sp_',segments_pitches.shape[1]))\n",
    "    st_df = pd.DataFrame(segments_timbre ,columns=var_list('st_',segments_timbre .shape[1]))\n",
    "    \n",
    "    # merge these single dataframes into one single row dataframe\n",
    "    ret = pd.concat([\n",
    "            # retrieve a single row dataframe from `/metadata/songs`\n",
    "            pd.DataFrame(store.root.metadata.songs.read(), \n",
    "                         columns=metadata_vars),\n",
    "            # retrieve a single row dataframe from `/analysis/songs`\n",
    "            pd.DataFrame(store.root.analysis.songs.read(), \n",
    "                         columns=analysis_vars),\n",
    "            #at_df, \n",
    "            bc_df, \n",
    "            sp_df,\n",
    "            st_df],\n",
    "            axis=1) # `axes=1` means stack the dataframes horizontally \n",
    "    # close the HDF5 file\n",
    "    store.close()\n",
    "    # return the merged dataframe\n",
    "    return(ret)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the list of (10,000) HDF5 (.h5) files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `path` variable stores the root of the directory tree containing all of the song files. The function `get_filenames` returns a multi-level list, which is flattened using `unlist` and stored in variable `filenames` as a list of full-path filenames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'MillionSongSubset/data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-d7b8d9ad308e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"MillionSongSubset/data\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mfilenames\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_filenames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mfilenames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-31-c161f6eeb5be>\u001b[0m in \u001b[0;36mget_filenames\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m      4\u001b[0m             \u001b[1;32melse\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"/\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mentry\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mentry\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m             \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscandir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m            ])\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'MillionSongSubset/data'"
     ]
    }
   ],
   "source": [
    "path = \"MillionSongSubset/data\"\n",
    "filenames = unlist(unlist(unlist(get_filenames(path))))\n",
    "filenames[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store in the `filenames` variable only the files with extension `.h5`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MillionSongSubset/data/A/A/A/TRAAAAW128F429D538.h5',\n",
       " 'MillionSongSubset/data/A/A/A/TRAAABD128F429CF47.h5']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = re.compile(\"\\.h5$\")\n",
    "filenames = [filename for filename \n",
    "             in filenames if p.search(filename)]\n",
    "filenames[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get lists of variables from `/metadata/songs` and `/analysis/songs`\n",
    "\n",
    "The two tables `/metadata/songs` and `/analysis/songs` provide data that is easy to load into a dataframe. Their variables are displayed below so we know which to choose or omit when creating the corresponding dataframes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `/metadata/songs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('analyzer_version', 'S32'), ('artist_7digitalid', '<i4'), ('artist_familiarity', '<f8'), ('artist_hotttnesss', '<f8'), ('artist_id', 'S32'), ('artist_latitude', '<f8'), ('artist_location', 'S1024'), ('artist_longitude', '<f8'), ('artist_mbid', 'S40'), ('artist_name', 'S1024'), ('artist_playmeid', '<i4'), ('genre', 'S1024'), ('idx_artist_terms', '<i4'), ('idx_similar_artists', '<i4'), ('release', 'S1024'), ('release_7digitalid', '<i4'), ('song_hotttnesss', '<f8'), ('song_id', 'S32'), ('title', 'S1024'), ('track_7digitalid', '<i4')]\n"
     ]
    }
   ],
   "source": [
    "tmp=pd.HDFStore(filenames[1])\n",
    "print(tmp.root.metadata.songs.read().dtype)\n",
    "tmp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `/analysis/songs`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the `make_1row_df` function on the fourth file\n",
    "\n",
    "We are currently only pulling data from `/metadata/songs` and `/analysis/songs`. \n",
    "\n",
    "Later we will pull additional data from the file. There are three types of data we can retreive:\n",
    "\n",
    "1. From `/metadata` there are three lists: `artist_terms`, `artist_terms_freq`, `artist_terms_weight`\n",
    "1. From `/analysis` there is information about _tatums_, _beats_, _segments_, _bars_, _timbre_ and _pitch_\n",
    "1. From `/musicbrainz` there should be tags, but I don't think there are any values here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist_familiarity</th>\n",
       "      <th>artist_hotttnesss</th>\n",
       "      <th>song_hotttnesss</th>\n",
       "      <th>title</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>artist_location</th>\n",
       "      <th>release</th>\n",
       "      <th>artist_longitude</th>\n",
       "      <th>artist_latitude</th>\n",
       "      <th>duration</th>\n",
       "      <th>...</th>\n",
       "      <th>st_26</th>\n",
       "      <th>st_27</th>\n",
       "      <th>st_28</th>\n",
       "      <th>st_29</th>\n",
       "      <th>st_30</th>\n",
       "      <th>st_31</th>\n",
       "      <th>st_32</th>\n",
       "      <th>st_33</th>\n",
       "      <th>st_34</th>\n",
       "      <th>st_35</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.630382</td>\n",
       "      <td>0.454231</td>\n",
       "      <td>NaN</td>\n",
       "      <td>b'Something Girls'</td>\n",
       "      <td>b'Adam Ant'</td>\n",
       "      <td>b'London, England'</td>\n",
       "      <td>b'Friend Or Foe'</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>233.40363</td>\n",
       "      <td>...</td>\n",
       "      <td>103.23</td>\n",
       "      <td>-17.005</td>\n",
       "      <td>-37.423</td>\n",
       "      <td>47.573</td>\n",
       "      <td>-0.734</td>\n",
       "      <td>25.383</td>\n",
       "      <td>-10.965</td>\n",
       "      <td>-44.947</td>\n",
       "      <td>10.023</td>\n",
       "      <td>-40.109</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 97 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   artist_familiarity  artist_hotttnesss  song_hotttnesss               title  \\\n",
       "0            0.630382           0.454231              NaN  b'Something Girls'   \n",
       "\n",
       "   artist_name     artist_location           release  artist_longitude  \\\n",
       "0  b'Adam Ant'  b'London, England'  b'Friend Or Foe'               NaN   \n",
       "\n",
       "   artist_latitude   duration   ...     st_26   st_27   st_28   st_29  st_30  \\\n",
       "0              NaN  233.40363   ...    103.23 -17.005 -37.423  47.573 -0.734   \n",
       "\n",
       "    st_31   st_32   st_33   st_34   st_35  \n",
       "0  25.383 -10.965 -44.947  10.023 -40.109  \n",
       "\n",
       "[1 rows x 97 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_1row_df(filename=filenames[3],\n",
    "                                metadata_vars=['artist_familiarity','artist_hotttnesss',\n",
    "                                           'song_hotttnesss','title','artist_name',\n",
    "                                           'artist_location','release',\n",
    "                                           'artist_longitude','artist_latitude'],\n",
    "                            # Omit: genre\n",
    "                            analysis_vars=['duration','key','loudness','mode',\n",
    "                                           'tempo','time_signature'],\n",
    "                            # Omit: danceability, energy\n",
    "                            remove=False\n",
    "                           )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There is more data in the file than the data in `/metadata/songs` and `/analysis/songs`. \n",
    "\n",
    "See the `Dataset-MSS-pandas-explore` notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a list of 10,000 single row dataframes\n",
    "\n",
    "Because `remove=False` is specified the two lists of variables are retrieved from the two `Tables` displayed above. The result of this command is a list of 10,000 single row dataframes with columns indicated. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It may take up to twenty (20) minutes to create `mss_df_list` with the current set of variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, (1, 96))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mss_df_list = [make_1row_df(filename=filename,\n",
    "                            metadata_vars=['artist_familiarity','artist_hotttnesss',\n",
    "                                           'song_hotttnesss','title',\n",
    "                                           'artist_location','release',\n",
    "                                           'artist_longitude','artist_latitude'],\n",
    "                            # Omit: genre\n",
    "                            analysis_vars=['duration','key','loudness','mode',\n",
    "                                           'tempo','time_signature'],\n",
    "                            # Omit: danceability, energy\n",
    "                            remove=False\n",
    "                           )\n",
    "                for filename in filenames[0:10000] # get data from all 10,000 files\n",
    "              ]\n",
    "len(mss_df_list), mss_df_list[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mss_df_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge all dataframes of `mss_df_list` into a single dataframe stored in `mss_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mss_df = pd.concat(mss_df_list,axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the head of the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist_familiarity</th>\n",
       "      <th>artist_hotttnesss</th>\n",
       "      <th>artist_latitude</th>\n",
       "      <th>artist_location</th>\n",
       "      <th>artist_longitude</th>\n",
       "      <th>bc_0</th>\n",
       "      <th>bc_1</th>\n",
       "      <th>bc_2</th>\n",
       "      <th>bc_3</th>\n",
       "      <th>bc_4</th>\n",
       "      <th>...</th>\n",
       "      <th>st_35</th>\n",
       "      <th>st_4</th>\n",
       "      <th>st_5</th>\n",
       "      <th>st_6</th>\n",
       "      <th>st_7</th>\n",
       "      <th>st_8</th>\n",
       "      <th>st_9</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.581794</td>\n",
       "      <td>0.401998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>b'California - LA'</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.643</td>\n",
       "      <td>0.746</td>\n",
       "      <td>0.722</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.091</td>\n",
       "      <td>...</td>\n",
       "      <td>-21.079</td>\n",
       "      <td>57.491</td>\n",
       "      <td>-50.067</td>\n",
       "      <td>14.833</td>\n",
       "      <td>5.359</td>\n",
       "      <td>-27.228</td>\n",
       "      <td>0.973</td>\n",
       "      <td>92.198</td>\n",
       "      <td>4</td>\n",
       "      <td>b\"I Didn't Mean To\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.630630</td>\n",
       "      <td>0.417500</td>\n",
       "      <td>35.14968</td>\n",
       "      <td>b'Memphis, TN'</td>\n",
       "      <td>-90.04892</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.404</td>\n",
       "      <td>0.011</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.048</td>\n",
       "      <td>57.491</td>\n",
       "      <td>-50.067</td>\n",
       "      <td>14.833</td>\n",
       "      <td>5.359</td>\n",
       "      <td>-27.228</td>\n",
       "      <td>0.973</td>\n",
       "      <td>121.274</td>\n",
       "      <td>4</td>\n",
       "      <td>b'Soul Deep'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.487357</td>\n",
       "      <td>0.343428</td>\n",
       "      <td>NaN</td>\n",
       "      <td>b''</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.980</td>\n",
       "      <td>0.399</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.422</td>\n",
       "      <td>...</td>\n",
       "      <td>4.562</td>\n",
       "      <td>57.482</td>\n",
       "      <td>-50.069</td>\n",
       "      <td>14.839</td>\n",
       "      <td>5.352</td>\n",
       "      <td>-27.227</td>\n",
       "      <td>0.975</td>\n",
       "      <td>100.070</td>\n",
       "      <td>1</td>\n",
       "      <td>b'Amor De Cabaret'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.630382</td>\n",
       "      <td>0.454231</td>\n",
       "      <td>NaN</td>\n",
       "      <td>b'London, England'</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.114</td>\n",
       "      <td>...</td>\n",
       "      <td>-40.109</td>\n",
       "      <td>56.300</td>\n",
       "      <td>202.348</td>\n",
       "      <td>68.838</td>\n",
       "      <td>-33.635</td>\n",
       "      <td>-24.275</td>\n",
       "      <td>92.399</td>\n",
       "      <td>119.293</td>\n",
       "      <td>4</td>\n",
       "      <td>b'Something Girls'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.651046</td>\n",
       "      <td>0.401724</td>\n",
       "      <td>NaN</td>\n",
       "      <td>b''</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.409</td>\n",
       "      <td>0.639</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.016</td>\n",
       "      <td>...</td>\n",
       "      <td>8.708</td>\n",
       "      <td>54.144</td>\n",
       "      <td>-50.189</td>\n",
       "      <td>18.536</td>\n",
       "      <td>5.384</td>\n",
       "      <td>-26.271</td>\n",
       "      <td>2.826</td>\n",
       "      <td>129.738</td>\n",
       "      <td>4</td>\n",
       "      <td>b'Face the Ashes'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 96 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   artist_familiarity  artist_hotttnesss  artist_latitude     artist_location  \\\n",
       "0            0.581794           0.401998              NaN  b'California - LA'   \n",
       "1            0.630630           0.417500         35.14968      b'Memphis, TN'   \n",
       "2            0.487357           0.343428              NaN                 b''   \n",
       "3            0.630382           0.454231              NaN  b'London, England'   \n",
       "4            0.651046           0.401724              NaN                 b''   \n",
       "\n",
       "   artist_longitude   bc_0   bc_1   bc_2   bc_3   bc_4         ...           \\\n",
       "0               NaN  0.643  0.746  0.722  0.095  0.091         ...            \n",
       "1         -90.04892  0.007  0.259  0.172  0.404  0.011         ...            \n",
       "2               NaN  0.980  0.399  0.185  0.270  0.422         ...            \n",
       "3               NaN  0.017  0.050  0.014  0.008  0.114         ...            \n",
       "4               NaN  0.175  0.409  0.639  0.067  0.016         ...            \n",
       "\n",
       "    st_35    st_4     st_5    st_6    st_7    st_8    st_9    tempo  \\\n",
       "0 -21.079  57.491  -50.067  14.833   5.359 -27.228   0.973   92.198   \n",
       "1  -5.048  57.491  -50.067  14.833   5.359 -27.228   0.973  121.274   \n",
       "2   4.562  57.482  -50.069  14.839   5.352 -27.227   0.975  100.070   \n",
       "3 -40.109  56.300  202.348  68.838 -33.635 -24.275  92.399  119.293   \n",
       "4   8.708  54.144  -50.189  18.536   5.384 -26.271   2.826  129.738   \n",
       "\n",
       "   time_signature                title  \n",
       "0               4  b\"I Didn't Mean To\"  \n",
       "1               4         b'Soul Deep'  \n",
       "2               1   b'Amor De Cabaret'  \n",
       "3               4   b'Something Girls'  \n",
       "4               4    b'Face the Ashes'  \n",
       "\n",
       "[5 rows x 96 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mss_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check its dimensions (shape) and its variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (10000, 96)\n",
      "columns: ['artist_familiarity' 'artist_hotttnesss' 'artist_latitude'\n",
      " 'artist_location' 'artist_longitude' 'bc_0' 'bc_1' 'bc_2' 'bc_3' 'bc_4'\n",
      " 'bc_5' 'bc_6' 'bc_7' 'bc_8' 'bc_9' 'duration' 'key' 'loudness' 'mode'\n",
      " 'release' 'song_hotttnesss' 'sp_0' 'sp_1' 'sp_10' 'sp_11' 'sp_12' 'sp_13'\n",
      " 'sp_14' 'sp_15' 'sp_16' 'sp_17' 'sp_18' 'sp_19' 'sp_2' 'sp_20' 'sp_21'\n",
      " 'sp_22' 'sp_23' 'sp_24' 'sp_25' 'sp_26' 'sp_27' 'sp_28' 'sp_29' 'sp_3'\n",
      " 'sp_30' 'sp_31' 'sp_32' 'sp_33' 'sp_34' 'sp_35' 'sp_4' 'sp_5' 'sp_6'\n",
      " 'sp_7' 'sp_8' 'sp_9' 'st_0' 'st_1' 'st_10' 'st_11' 'st_12' 'st_13' 'st_14'\n",
      " 'st_15' 'st_16' 'st_17' 'st_18' 'st_19' 'st_2' 'st_20' 'st_21' 'st_22'\n",
      " 'st_23' 'st_24' 'st_25' 'st_26' 'st_27' 'st_28' 'st_29' 'st_3' 'st_30'\n",
      " 'st_31' 'st_32' 'st_33' 'st_34' 'st_35' 'st_4' 'st_5' 'st_6' 'st_7' 'st_8'\n",
      " 'st_9' 'tempo' 'time_signature' 'title']\n"
     ]
    }
   ],
   "source": [
    "print('shape:',mss_df.shape)\n",
    "print('columns:',mss_df.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some changes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make  `key` and `time_signature` variables categorical\n",
    "\n",
    "Leave `mode` as numeric. It mayb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(category, dtype('float64'), category)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mss_df['mode']            = mss_df['mode']           .astype('float64')\n",
    "mss_df['key']             = mss_df['key']            .astype('category')\n",
    "mss_df['time_signature']  = mss_df['time_signature'] .astype('category')\n",
    "mss_df['key'].dtype, mss_df['mode'].dtype, mss_df['time_signature'].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dummy variables from categorical variables `key` and `time_signature`\n",
    "\n",
    "The `mode` variable is already binary. \n",
    "\n",
    "The `key` and `time_signature` variables are removed with this next command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "mss_df = pd.get_dummies(mss_df, \n",
    "                        columns=['key','time_signature'], \n",
    "                        prefix=['k','ts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "artist_familiarity    float64\n",
       "artist_hotttnesss     float64\n",
       "artist_latitude       float64\n",
       "artist_location        object\n",
       "artist_longitude      float64\n",
       "bc_0                  float64\n",
       "bc_1                  float64\n",
       "bc_2                  float64\n",
       "bc_3                  float64\n",
       "bc_4                  float64\n",
       "bc_5                  float64\n",
       "bc_6                  float64\n",
       "bc_7                  float64\n",
       "bc_8                  float64\n",
       "bc_9                  float64\n",
       "duration              float64\n",
       "loudness              float64\n",
       "mode                  float64\n",
       "release                object\n",
       "song_hotttnesss       float64\n",
       "sp_0                  float64\n",
       "sp_1                  float64\n",
       "sp_10                 float64\n",
       "sp_11                 float64\n",
       "sp_12                 float64\n",
       "sp_13                 float64\n",
       "sp_14                 float64\n",
       "sp_15                 float64\n",
       "sp_16                 float64\n",
       "sp_17                 float64\n",
       "                       ...   \n",
       "st_32                 float64\n",
       "st_33                 float64\n",
       "st_34                 float64\n",
       "st_35                 float64\n",
       "st_4                  float64\n",
       "st_5                  float64\n",
       "st_6                  float64\n",
       "st_7                  float64\n",
       "st_8                  float64\n",
       "st_9                  float64\n",
       "tempo                 float64\n",
       "title                  object\n",
       "k_0                   float64\n",
       "k_1                   float64\n",
       "k_2                   float64\n",
       "k_3                   float64\n",
       "k_4                   float64\n",
       "k_5                   float64\n",
       "k_6                   float64\n",
       "k_7                   float64\n",
       "k_8                   float64\n",
       "k_9                   float64\n",
       "k_10                  float64\n",
       "k_11                  float64\n",
       "ts_0                  float64\n",
       "ts_1                  float64\n",
       "ts_3                  float64\n",
       "ts_4                  float64\n",
       "ts_5                  float64\n",
       "ts_7                  float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mss_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the table `mss_df` in a _pickle_ file\n",
    "\n",
    "First set the folder to save to and load from. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_load_path = 'MillionSongSubset/data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save `mss_df` to a _pickle_ file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mss_df.to_pickle(save_load_path+'/mss_df.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load `mss_df` from the _pickle_ file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mss_df = pd.read_pickle(save_load_path+'/mss_df.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now check that we retrieved the same number of rows and variables we expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (10000, 112)\n",
      "columns: ['artist_familiarity' 'artist_hotttnesss' 'artist_latitude'\n",
      " 'artist_location' 'artist_longitude' 'bc_0' 'bc_1' 'bc_2' 'bc_3' 'bc_4'\n",
      " 'bc_5' 'bc_6' 'bc_7' 'bc_8' 'bc_9' 'duration' 'loudness' 'mode' 'release'\n",
      " 'song_hotttnesss' 'sp_0' 'sp_1' 'sp_10' 'sp_11' 'sp_12' 'sp_13' 'sp_14'\n",
      " 'sp_15' 'sp_16' 'sp_17' 'sp_18' 'sp_19' 'sp_2' 'sp_20' 'sp_21' 'sp_22'\n",
      " 'sp_23' 'sp_24' 'sp_25' 'sp_26' 'sp_27' 'sp_28' 'sp_29' 'sp_3' 'sp_30'\n",
      " 'sp_31' 'sp_32' 'sp_33' 'sp_34' 'sp_35' 'sp_4' 'sp_5' 'sp_6' 'sp_7' 'sp_8'\n",
      " 'sp_9' 'st_0' 'st_1' 'st_10' 'st_11' 'st_12' 'st_13' 'st_14' 'st_15'\n",
      " 'st_16' 'st_17' 'st_18' 'st_19' 'st_2' 'st_20' 'st_21' 'st_22' 'st_23'\n",
      " 'st_24' 'st_25' 'st_26' 'st_27' 'st_28' 'st_29' 'st_3' 'st_30' 'st_31'\n",
      " 'st_32' 'st_33' 'st_34' 'st_35' 'st_4' 'st_5' 'st_6' 'st_7' 'st_8' 'st_9'\n",
      " 'tempo' 'title' 'k_0' 'k_1' 'k_2' 'k_3' 'k_4' 'k_5' 'k_6' 'k_7' 'k_8'\n",
      " 'k_9' 'k_10' 'k_11' 'ts_0' 'ts_1' 'ts_3' 'ts_4' 'ts_5' 'ts_7']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "artist_familiarity    float64\n",
       "artist_hotttnesss     float64\n",
       "artist_latitude       float64\n",
       "artist_location        object\n",
       "artist_longitude      float64\n",
       "bc_0                  float64\n",
       "bc_1                  float64\n",
       "bc_2                  float64\n",
       "bc_3                  float64\n",
       "bc_4                  float64\n",
       "bc_5                  float64\n",
       "bc_6                  float64\n",
       "bc_7                  float64\n",
       "bc_8                  float64\n",
       "bc_9                  float64\n",
       "duration              float64\n",
       "loudness              float64\n",
       "mode                  float64\n",
       "release                object\n",
       "song_hotttnesss       float64\n",
       "sp_0                  float64\n",
       "sp_1                  float64\n",
       "sp_10                 float64\n",
       "sp_11                 float64\n",
       "sp_12                 float64\n",
       "sp_13                 float64\n",
       "sp_14                 float64\n",
       "sp_15                 float64\n",
       "sp_16                 float64\n",
       "sp_17                 float64\n",
       "                       ...   \n",
       "st_32                 float64\n",
       "st_33                 float64\n",
       "st_34                 float64\n",
       "st_35                 float64\n",
       "st_4                  float64\n",
       "st_5                  float64\n",
       "st_6                  float64\n",
       "st_7                  float64\n",
       "st_8                  float64\n",
       "st_9                  float64\n",
       "tempo                 float64\n",
       "title                  object\n",
       "k_0                   float64\n",
       "k_1                   float64\n",
       "k_2                   float64\n",
       "k_3                   float64\n",
       "k_4                   float64\n",
       "k_5                   float64\n",
       "k_6                   float64\n",
       "k_7                   float64\n",
       "k_8                   float64\n",
       "k_9                   float64\n",
       "k_10                  float64\n",
       "k_11                  float64\n",
       "ts_0                  float64\n",
       "ts_1                  float64\n",
       "ts_3                  float64\n",
       "ts_4                  float64\n",
       "ts_5                  float64\n",
       "ts_7                  float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('shape:',mss_df.shape)\n",
    "print('columns:',mss_df.columns.values)\n",
    "mss_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
